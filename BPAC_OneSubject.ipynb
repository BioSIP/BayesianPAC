{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bayesian PAC (One Subject)</h1>\n",
    "\n",
    "The <strong>Phase-Amplitude Coupling (PAC) analysis</strong> is a technique used in neuroscience to study the interaction between different frequency bands in brain signals (in our case EEG signals).\n",
    "\n",
    "The <strong>Bayesian PAC</strong> approach that we are trying to develop is an extension that uses Bayesian theory <strong>to provide a probabilistic interpretation of neural connections</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initialization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorpac\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import gaussian_kde, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Global Vars</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nChannels = 31     # We have 32 channels though one (Cz) is used as reference for offset and normalization purposes.\n",
    "G_Fs = 500           # fSampling (Hz).\n",
    "G_Alpha = 0.05       # Reference p-Value to evaluate the z-Score threshold.\n",
    "G_nSurrogates = 200  # Number of surrogates to evaluate.\n",
    "G_nFragments = 25    # Number of fragments (should be divisor of the total lenght of EEG signals).\n",
    "G_nBins = 40         # Number of bins for the histogram of significant PAC values.\n",
    "G_EEG_labels = ['Fp1','Fp2','F7','F3','Fz','F4','F8','FC5','FC1','FC2','FC6','T7','C3','C4','T8','TP9','CP5','CP1','CP2','CP6','TP10','P7','P3','PZ','P4','P8','PO9','O1','OZ','O2','PO10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading the EEG signal from the subject of interest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the EEG signal we want to evaluate\n",
    "fName = 'your_eeg_signal_sample.npy'\n",
    "fName = '043_C7_8b.npy'\n",
    "npy_load = np.load('DDBB/'+fName,mmap_mode='r',allow_pickle=True) # Replace 'DDBB/' with the path to your DDBB.\n",
    "npy_data = np.nan_to_num(npy_load.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auxiliary Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filtering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtered_eeg(signal, time_range, labels, n_channels, title):\n",
    "    \"\"\"\n",
    "    Plot filtered EEG signals.\n",
    "    \n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): EEG signal data.\n",
    "    time_range (list): Time range to plot.\n",
    "    labels (list): EEG channel labels.\n",
    "    n_channels (int): Number of EEG channels.\n",
    "    title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    t = np.linspace(time_range[0], time_range[1], time_range[1] - time_range[0] + 1, dtype=int)\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=8, figsize=(15, 10))\n",
    "    my_colors = sns.color_palette(\"rocket\", n_colors=n_channels)\n",
    "\n",
    "    for i in range(n_channels):\n",
    "        ax.flatten()[i].plot(t, signal[i, t], alpha=0.75, linewidth=0.75, color=my_colors[i], label=labels[i])\n",
    "        ax.flatten()[i].legend(loc='upper right', fontsize='small')\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.savefig('Figures/temp_signal_'+title.replace(\" \", \"\")+'.eps', format='eps', bbox_inches='tight')\n",
    "    plt.savefig('Figures/temp_signal_'+title.replace(\" \", \"\")+'.png', format='png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pac_heatmap(significant_pac_values, labels, is_fragmented=False):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of significant PAC values.\n",
    "    \n",
    "    Parameters:\n",
    "    significant_pac_values (numpy.ndarray): Significant PAC values between pairs of electrodes.\n",
    "    labels (list): EEG channel labels.\n",
    "    is_fragmented (bool): If True, significant_pac_values is assumed to be averaged values from fragments.\n",
    "    \"\"\"\n",
    "    title = 'Significant PAC Values Heatmap (averaged results of the fragments)' if is_fragmented else 'Significant PAC Values Heatmap (Complete Signal)'\n",
    "    \n",
    "    if is_fragmented:\n",
    "        averaged_pac_values = np.mean(significant_pac_values, axis=2)\n",
    "    else:\n",
    "        averaged_pac_values = significant_pac_values\n",
    "    \n",
    "    pac_df = pd.DataFrame(averaged_pac_values * 1e5, index=labels, columns=labels)  # Scale PAC values\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(pac_df, annot=True, cmap=\"rocket\", linewidths=.5, fmt=\".1f\", annot_kws={\"size\": 6})\n",
    "    cbar = plt.gcf().axes[-1]\n",
    "    cbar.set_ylabel('PAC Value (x10⁻⁵)', rotation=90, fontsize=12)\n",
    "    cbar.yaxis.set_label_position('right')\n",
    "    plt.title(title)\n",
    "\n",
    "     # Set labels\n",
    "    plt.xlabel('Sources', fontsize=12)\n",
    "    plt.ylabel('Destinations', fontsize=12)\n",
    "\n",
    "    if is_fragmented:\n",
    "        trail_string = 'fragmented'\n",
    "    else:\n",
    "        trail_string = 'full'\n",
    "    plt.savefig('Figures/significant_pac_heatmap_'+trail_string+'.eps', format='eps', bbox_inches='tight')\n",
    "    plt.savefig('Figures/significant_pac_heatmap_'+trail_string+'.png', format='png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_bayesian_pac_heatmap(P_i_given_x, labels, save_str='default'):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of the Bayesian PAC values P(i|x) as percentages.\n",
    "    \n",
    "    Parameters:\n",
    "    P_i_given_x (numpy.ndarray): The Bayesian PAC values matrix of shape (destinations, sources).\n",
    "    labels (list): List of labels for the source and destination electrodes.\n",
    "    save_str (str): String used for saving the figures.\n",
    "    \"\"\"\n",
    "    # Convert the matrix to percentages\n",
    "    P_i_given_x_percentage = P_i_given_x * 100\n",
    "    \n",
    "    # Calculate the maximum value and round up to nearest multiple of 2\n",
    "    max_value = np.ceil(np.max(P_i_given_x_percentage) / 2) * 2\n",
    "    \n",
    "    # Create tick sequence from 0 to max_value\n",
    "    ticks = np.arange(0, max_value + 2, 2)  # +2 to include the max value\n",
    "    \n",
    "    # Set vmax to the maximum tick value for consistent scale\n",
    "    vmax = ticks[-1]\n",
    "    \n",
    "    # Convert the matrix to a DataFrame for easier plotting with seaborn\n",
    "    P_i_given_x_df = pd.DataFrame(P_i_given_x_percentage, index=labels, columns=labels)\n",
    "\n",
    "    # Create the figure with specific size\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Heatmap without annotations\n",
    "    # ax = sns.heatmap(P_i_given_x_df, \n",
    "    #                  annot=False, \n",
    "    #                  cmap=\"rocket\", \n",
    "    #                  linewidths=.5,\n",
    "    #                  vmin=0,\n",
    "    #                  vmax=vmax)\n",
    "    \n",
    "    # Heatmap with annotations\n",
    "    ax = sns.heatmap(P_i_given_x_df,\n",
    "                     annot=True,\n",
    "                     cmap=\"rocket\",\n",
    "                     linewidths=.5,\n",
    "                     vmin=0,\n",
    "                     vmax=vmax,\n",
    "                     fmt=\".1f\",\n",
    "                     annot_kws={\"size\": 6})\n",
    "\n",
    "    # Set labels\n",
    "    plt.xlabel('Sources', fontsize=12)\n",
    "    plt.ylabel('Destinations', fontsize=12)\n",
    "    \n",
    "    # Modify colorbar\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    colorbar.set_label('Bayesian PAC Values P(i|x)', fontsize=12)\n",
    "    \n",
    "    # Set percentage ticks on colorbar\n",
    "    colorbar.set_ticks(ticks)\n",
    "    colorbar.set_ticklabels([f'{tick}%' for tick in ticks])\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'Figures/bayesian_pac_heatmap_{save_str}.eps', format='eps', bbox_inches='tight')\n",
    "    plt.savefig(f'Figures/bayesian_pac_heatmap_{save_str}.png', format='png', bbox_inches='tight')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main Pipeline</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Filtering the EEG signal on interest bands</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example filtering Theta and Gamma bands\n",
    "data_theta = mne.filter.filter_data(npy_data, G_Fs, 4, 8)\n",
    "data_gamma = mne.filter.filter_data(npy_data, G_Fs, 30, 80)\n",
    "\n",
    "# Plot filtered EEG signals (Optional. This is an example showing a segment of the EEG signal and its filtered Theta and Gamma bands)\n",
    "plot_filtered_eeg(npy_data, [25000, 25400], G_EEG_labels, G_nChannels, \"Not filtered\")\n",
    "plot_filtered_eeg(data_theta, [25000, 25400], G_EEG_labels, G_nChannels, \"Theta band\")\n",
    "plot_filtered_eeg(data_gamma, [25000, 25400], G_EEG_labels, G_nChannels, \"Gamma band\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2: Hilbert Transform</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Hilbert Transform to obtain the phase (ip) and the amplitude (ia) of Theta/Gamma bands\n",
    "ip_theta = np.angle(hilbert(data_theta, axis=1)) # Results present a size: [nChannels,Time]\n",
    "ia_gamma = np.abs(hilbert(data_gamma, axis=1))   # Results present a size: [nChannels,Time]\n",
    "\n",
    "# Reshape to add the n_epochs dimension\n",
    "ip_theta = ip_theta[:, np.newaxis, :]\n",
    "ia_gamma = ia_gamma[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3: Segmentation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_fLength = int(np.shape(npy_data)[1]/G_nFragments) # Fragment length\n",
    "\n",
    "# Create arrays for fragments\n",
    "ip_theta_fragments = np.zeros((G_nChannels, G_nFragments, L_fLength))\n",
    "ia_gamma_fragments = np.zeros((G_nChannels, G_nFragments, L_fLength))\n",
    "\n",
    "# Filling the matrices with the fragments\n",
    "for i in range(G_nFragments):\n",
    "    ip_theta_fragments[:, i, :] = ip_theta[:, 0, i * L_fLength: (i + 1) * L_fLength]\n",
    "    ia_gamma_fragments[:, i, :] = ia_gamma[:, 0, i * L_fLength: (i + 1) * L_fLength]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 4: Computing PAC values using TensorPAC with surrogates</h3>\n",
    "\n",
    "The PAC analyzes the relationship between the phase of a low-frequency oscillation (e.g., theta: 4-8 Hz) and the amplitude of a high-frequency oscillation (e.g., gamma: 30-80 Hz). The concept is that the phase of the low frequency signal can modulate the amplitude of the high frequency signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the threshold for significance tests using z-scores (Bonferroni correction)\n",
    "L_alpha_Bonferroni = G_Alpha/G_nFragments\n",
    "G_zThreshold_Bonferroni = norm.ppf(1 - L_alpha_Bonferroni)\n",
    "print(f\"z-Score threshold for the fragmented signal ({G_nFragments} fragments) [Bonferroni-Correction]: {G_zThreshold_Bonferroni}\")\n",
    "\n",
    "# Initializing arrays to store results (fragments)\n",
    "pac_values_fragments = np.zeros((G_nChannels, G_nChannels, G_nFragments))\n",
    "surrogate_pac_values_fragments = np.zeros((G_nChannels, G_nChannels, G_nSurrogates, G_nFragments))\n",
    "p_values_fragments = np.zeros((G_nChannels, G_nChannels, G_nFragments))\n",
    "\n",
    "# Initialize PAC object with surrogates\n",
    "p = tensorpac.Pac(idpac=(2, 2, 0), f_pha=(4, 8), f_amp=(30, 80), dcomplex='wavelet', width=7)\n",
    "\n",
    "# Calculate PAC by fragments\n",
    "for frag in range(G_nFragments):\n",
    "    for i in range(G_nChannels):\n",
    "            for j in range(G_nChannels):\n",
    "                pac = p.fit(ip_theta_fragments[i, frag].reshape(1, 1, -1), \n",
    "                            ia_gamma_fragments[j, frag].reshape(1, 1, -1), \n",
    "                            n_perm=200, \n",
    "                            random_state=1234)\n",
    "                pac_values_fragments[i, j, frag] = p.pac[0][0][0]\n",
    "                surrogate_pac_values_fragments[i, j, :, frag] = p.surrogates.reshape(G_nSurrogates)\n",
    "                p_values_fragments[i, j, frag] = p.pvalues[0][0]\n",
    "\n",
    "# Calculate z-scores and determine significant PAC values per fragments\n",
    "z_scores_fragments = np.zeros((G_nChannels, G_nChannels, G_nFragments))\n",
    "significant_pac_values_fragments = np.zeros((G_nChannels, G_nChannels, G_nFragments))\n",
    "\n",
    "for frag in range(G_nFragments):\n",
    "    for i in range(G_nChannels):\n",
    "        for j in range(G_nChannels):\n",
    "            real_pac = pac_values_fragments[i, j, frag]\n",
    "            surrogate_mean = np.mean(surrogate_pac_values_fragments[i, j, :, frag])\n",
    "            surrogate_std = np.std(surrogate_pac_values_fragments[i, j, :, frag])\n",
    "            if surrogate_std == 0:\n",
    "                z_scores_fragments[i, j, frag] = 0  # Avoid division by zero\n",
    "            else:\n",
    "                z_scores_fragments[i, j, frag] = (real_pac - surrogate_mean) / surrogate_std\n",
    "\n",
    "            if abs(z_scores_fragments[i, j, frag]) > G_zThreshold_Bonferroni:\n",
    "                significant_pac_values_fragments[i, j, frag] = pac_values_fragments[i, j, frag]\n",
    "\n",
    "# Check dimensions\n",
    "print(np.shape(z_scores_fragments))                 # Should be (G_nChannels, G_nChannels, G_nFragments)\n",
    "print(np.shape(significant_pac_values_fragments))   # Should be (G_nChannels, G_nChannels, G_nFragments)\n",
    "\n",
    "# Significant PACs of fragments\n",
    "plot_pac_heatmap(significant_pac_values_fragments, G_EEG_labels, is_fragmented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 5: Bayes' Theorem</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <strong>Bayesian PAC</strong> introduces a probabilistic perspective to evaluate the connections between different nodes in the brain. It uses Bayes' Theorem to calculate the probability that a target node $i$ is activated, conditional on a source node $x$ being exerting an influence.\n",
    "\n",
    "Our objective is to determine the term $P(i∣x)$ which represents the probability that target node $i$ is activated given that source node $x$ is exerting an influence.\n",
    "\n",
    "$$P(i|x) = \\frac{P(x|i) \\cdot P(i)}{P(x)} = \\frac{P(x|i)·P(i)}{\\sum\\limits_i P(x|i) \\cdot P(i)}$$\n",
    "\n",
    "where...\n",
    "\n",
    "* $P(i)$: Probability (a priori) of activation at electrode $i$. This means, $P(i)$ represents the probability of having the destination node $i$ activated regardless of any source node $x$. Using other words, this term represents the proportion of times that the target node $i$ shows significant activation across all fragments and node pairs.\n",
    "\n",
    "$$P(i) = \\frac{\\# \\text{significant PACs at electrode } i \\text{ with origin any other electrode}}{\\# \\text{significant PACs}}$$\n",
    "\n",
    "* $P(x)$: Probability of observing an influence of source node $x$ in general.\n",
    "\n",
    "* $P(x∣i)$: indicates the probability of observing an influence of source node $x$ given that target node $i$ is activated. We can determine its value by using the probability density function (obtained using KDE) for electrode $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Histogram of significant PAC values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the significant PAC values matrix for fragments and remove zeros\n",
    "significant_pac_values_flat_fragments = significant_pac_values_fragments.flatten()\n",
    "significant_pac_values_flat_fragments = significant_pac_values_flat_fragments[significant_pac_values_flat_fragments > 0] * 1e5 # Scale to avoid problems with small values\n",
    "\n",
    "# Fit a KDE to the data\n",
    "kde_fragments = gaussian_kde(np.abs(significant_pac_values_flat_fragments)) # We make use only of absolute values\n",
    "\n",
    "# Fit a Gaussian distribution to the data\n",
    "mu_fragments, std_fragments = norm.fit(np.abs(significant_pac_values_flat_fragments)) # We make use only of absolute values\n",
    "\n",
    "# Plot the histogram with frequencies\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "n, bins, patches = ax1.hist(significant_pac_values_flat_fragments, bins=G_nBins, color='skyblue', edgecolor='black', rwidth=0.8)\n",
    "# Create a secondary y-axis to plot the KDE and Gaussian PDF\n",
    "ax2 = ax1.twinx()\n",
    "# Plot the KDE\n",
    "xmin, xmax = ax1.get_xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p_kde_fragments = kde_fragments(x)\n",
    "ax2.plot(x, p_kde_fragments, 'r', linewidth=2, label='KDE')\n",
    "# Plot the Gaussian PDF\n",
    "p_gauss_fragments = norm.pdf(x, mu_fragments, std_fragments)\n",
    "ax2.plot(x, p_gauss_fragments, 'm', linewidth=2, label='Gaussian PDF')\n",
    "# Set titles and labels\n",
    "ax1.set_title(\"Histogram of Significant PAC Values (Fragments)\")\n",
    "ax1.set_xlabel(\"PAC Value (x10⁻⁵)\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax2.set_ylabel(\"Probability Density\")\n",
    "ax1.grid(True)\n",
    "ax2.legend()\n",
    "plt.savefig('Figures/histogram_and_KDE.eps', format='eps', bbox_inches='tight')\n",
    "plt.savefig('Figures/histogram_and_KDE.png', format='png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Computing P(i)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(i) for each destination node\n",
    "significant_pac_counts_by_destination = np.zeros(G_nChannels)\n",
    "for frag in range(G_nFragments):\n",
    "    for i in range(G_nChannels):\n",
    "        for j in range(G_nChannels):\n",
    "            if significant_pac_values_fragments[i, j, frag] > 0:\n",
    "                significant_pac_counts_by_destination[i] += 1\n",
    "total_significant_pacs = np.sum(significant_pac_counts_by_destination)\n",
    "P_i = significant_pac_counts_by_destination / total_significant_pacs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Computing P(x|i)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize P(x|i) and the counters necessary to obtain significant values.\n",
    "P_x_given_i = np.zeros((G_nChannels, G_nChannels, G_nFragments))\n",
    "P_x_given_i_significant_counts = np.zeros((G_nChannels, G_nChannels))\n",
    "\n",
    "# Evaluate KDE for each significant PAC value\n",
    "for frag in range(G_nFragments):\n",
    "    for i in range(G_nChannels):\n",
    "        for j in range(G_nChannels):\n",
    "            if significant_pac_values_fragments[i, j, frag] > 0:\n",
    "                P_x_given_i[i, j, frag] = kde_fragments(significant_pac_values_fragments[i, j, frag] * 1e5).item()\n",
    "            else:\n",
    "                P_x_given_i[i, j, frag] = 0\n",
    "\n",
    "# Normalize P(x|i) by fragment and count significant values\n",
    "for frag in range(G_nFragments):\n",
    "    P_x_given_i_sum = np.sum(P_x_given_i[:, :, frag], axis=0)\n",
    "    P_x_given_i[:, :, frag] = np.divide(P_x_given_i[:, :, frag], P_x_given_i_sum, \n",
    "                                        out=np.zeros_like(P_x_given_i[:, :, frag]), \n",
    "                                        where=P_x_given_i_sum != 0)\n",
    "    P_x_given_i_significant_counts += (P_x_given_i[:, :, frag] > 0).astype(int)\n",
    "\n",
    "# Calculate the proportion of significant fragments for P(x|i)\n",
    "P_x_given_i_mean = P_x_given_i_significant_counts / G_nFragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Computing P(x)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(x) for each fragment\n",
    "P_x = np.zeros((G_nChannels, G_nFragments))\n",
    "for frag in range(G_nFragments):\n",
    "    P_x[:, frag] = np.dot(P_i, P_x_given_i[:, :, frag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Applying Bayes' Theorem</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(i|x) for each fragment using Bayes' Theorem and count the significant values\n",
    "P_i_given_x_fragments = np.zeros((G_nChannels, G_nChannels, G_nFragments))\n",
    "P_i_given_x_significant_counts = np.zeros((G_nChannels, G_nChannels))\n",
    "\n",
    "for frag in range(G_nFragments):\n",
    "    P_i_given_x_fragments[:, :, frag] = (P_x_given_i[:, :, frag].T * P_i).T\n",
    "    P_i_given_x_fragments[:, :, frag] = np.divide(P_i_given_x_fragments[:, :, frag], P_x[:, frag], \n",
    "                                                  out=np.zeros_like(P_i_given_x_fragments[:, :, frag]), \n",
    "                                                  where=P_x[:, frag] != 0)\n",
    "    P_i_given_x_significant_counts += (P_i_given_x_fragments[:, :, frag] > 0).astype(int)\n",
    "\n",
    "# Calculate the proportion of significant fragments\n",
    "P_i_given_x_mean = P_i_given_x_significant_counts / G_nFragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the results using the display functions\n",
    "plot_bayesian_pac_heatmap(P_i_given_x_mean, G_EEG_labels, 'fragmented-signal-aggregated-values')\n",
    "\n",
    "# (Optional) Apply a threshold to filter out the most robust connections\n",
    "P_i_given_x_thresholded = np.where(P_i_given_x_mean >= 0.1, P_i_given_x_mean, 0) # Only connections with proabilities >= 10% will be shown.\n",
    "plot_bayesian_pac_heatmap(P_i_given_x_thresholded, G_EEG_labels, 'fragmented-signal-aggregated-values-threshold')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
