{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bayesian PAC (Group Comparison)</h1>\n",
    "\n",
    "The objective of this code is to classify the subjects using the connections that have been found to be significant and/or tend to be significant. A non-parametric permutation test is then applied to evaluate whether the classification results are the result of chance or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initialization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.patches import Arc, Circle, ConnectionPatch\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Global Vars</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nChannels = 31       # We have 32 channels though one (Cz) is used as reference for offset and normalization purposes.\n",
    "G_Alpha = 0.1          # Reference p-Value to evaluate the z-Score threshold.\n",
    "G_Alpha_near = 0.25    # Reference p-Value to evaluate the z-Score threshold for near significant connections.\n",
    "G_nSurrogates = 200    # Number of surrogates to evaluate.\n",
    "G_nPermutations = 1000 # Number of iterations of the permutation test.\n",
    "G_EEG_labels = ['Fp1','Fp2','F7','F3','Fz','F4','F8','FC5','FC1','FC2','FC6','T7','C3','C4','T8','TP9','CP5','CP1','CP2','CP6','TP10','P7','P3','PZ','P4','P8','PO9','O1','OZ','O2','PO10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(Optional) Verification of the Bonferroni-corrected alpha selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of connections\n",
    "n_comparisons = G_nChannels*G_nChannels\n",
    "\n",
    "# Bonferroni-corrected alpha\n",
    "alpha_bonferroni = G_Alpha / n_comparisons\n",
    "z_alpha_bonferroni = norm.ppf(1 - alpha_bonferroni)\n",
    "print(f\"\\nFor G_Alpha = {G_Alpha} with {n_comparisons} comparisons:\")\n",
    "print(f\"Bonferroni-corrected alpha = {alpha_bonferroni:.4e}\")\n",
    "print(f\"Bonferroni-corrected z-score: {z_alpha_bonferroni:.4e}\")\n",
    "\n",
    "# Bonferroni-corrected alpha (near significant)\n",
    "alpha_bonferroni_near = G_Alpha_near / n_comparisons\n",
    "z_alpha_bonferroni_near = norm.ppf(1 - alpha_bonferroni_near)\n",
    "print(f\"\\nFor G_Alpha_near = {G_Alpha_near} with {n_comparisons} comparisons:\")\n",
    "print(f\"Bonferroni-corrected alpha_near = {alpha_bonferroni_near:.4e}\")\n",
    "print(f\"Bonferroni-corrected z-score_near: {z_alpha_bonferroni_near:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Auxiliary Functions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Classification</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for training and evaluating XGBoost\n",
    "def train_evaluate_xgboost(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost classifier on the given data.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "    y (numpy.ndarray): Response vector of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - accuracy (float): The accuracy score of the model on the test set.\n",
    "        - balanced_accuracy (float): The balanced accuracy score on the test set.\n",
    "        - auc (float): The AUC score on the test set.\n",
    "        - precision (float): The precision score on the test set.\n",
    "        - recall (float): The recall score (sensitivity) on the test set.\n",
    "        - specificity (float): The specificity score on the test set.\n",
    "        - f1 (float): The F1-score of the model on the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize the XGBoost classifier\n",
    "    model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate evaluation metrics on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)  # Sensitivity\n",
    "    specificity = recall_score(y_test, y_pred, pos_label=0, zero_division=1)  # Specificity\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "\n",
    "    # Return the evaluation metrics as a tuple\n",
    "    return accuracy, balanced_accuracy, auc, precision, recall, specificity, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Visualization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_connection_plot(ax, pos, node_radius, z_value, color='black', linewidth=6, center=(0,0)):\n",
    "    \"\"\"\n",
    "    Draws a self-connection as an arc between the intersection points of two circles:\n",
    "    the node circle and another one shifted towards the center of the connectogram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        Axis where to draw.\n",
    "    pos : tuple\n",
    "        (x, y) coordinates of the node.\n",
    "    node_radius : float\n",
    "        Radius of the node.\n",
    "    z_value : float\n",
    "        Z value to annotate (optional).\n",
    "    color : str\n",
    "        Color of the arc.\n",
    "    linewidth : float\n",
    "        Width of the arc.\n",
    "    center : tuple\n",
    "        Center of the connectogram.\n",
    "    \"\"\"\n",
    "    px, py = pos\n",
    "    cx, cy = center\n",
    "\n",
    "    # Vector towards the center\n",
    "    v = np.array([cx - px, cy - py])\n",
    "    v = v / np.linalg.norm(v)\n",
    "    # Center of the shifted circle\n",
    "    ghost_center = np.array(pos) + v * node_radius * 1.2\n",
    "\n",
    "    # Original and shifted circles\n",
    "    x0, y0 = pos\n",
    "    x1, y1 = ghost_center\n",
    "    r = node_radius\n",
    "\n",
    "    # Equation of intersection of two circles\n",
    "    d = np.linalg.norm(ghost_center - pos)\n",
    "    if d > 2*r:\n",
    "        # No intersection, abort\n",
    "        return\n",
    "\n",
    "    # Intersection points\n",
    "    a = d/2\n",
    "    h = np.sqrt(r**2 - a**2)\n",
    "    mid = (np.array(pos) + ghost_center) / 2\n",
    "    perp = np.array([-(y1-y0), x1-x0]) / d\n",
    "\n",
    "    inter1 = mid + h * perp\n",
    "    inter2 = mid - h * perp\n",
    "\n",
    "    # Angles of intersection points relative to the center of the shifted circle\n",
    "    angle1 = np.degrees(np.arctan2(inter1[1]-y1, inter1[0]-x1))\n",
    "    angle2 = np.degrees(np.arctan2(inter2[1]-y1, inter2[0]-x1))\n",
    "\n",
    "    # Choose the arc that passes closest to the center of the connectogram\n",
    "    # (smallest absolute angle relative to the direction to the center)\n",
    "    dir_to_center = np.degrees(np.arctan2(cy-y1, cx-x1))\n",
    "    # Determine arc direction\n",
    "    angle_diff = (angle2 - angle1) % 360\n",
    "    if abs((angle1 + angle_diff/2) - dir_to_center) > 90:\n",
    "        # Reverse direction if the arc doesn't pass through the center\n",
    "        angle1, angle2 = angle2, angle1\n",
    "\n",
    "    # Draw the arc\n",
    "    arc = Arc(ghost_center, 2*r, 2*r, angle=0, theta1=angle1, theta2=angle2,\n",
    "              color=color, lw=linewidth, zorder=10)\n",
    "    ax.add_patch(arc)\n",
    "\n",
    "    # Draw the arrow at the end of the arc\n",
    "    # Calculate end point and tangent\n",
    "    theta = np.radians(angle2)\n",
    "    end = np.array([x1 + r * np.cos(theta), y1 + r * np.sin(theta)])\n",
    "    tangent = np.array([-np.sin(theta), np.cos(theta)])\n",
    "    # Small offset for the arrow\n",
    "    arrow_start = end - tangent * node_radius * 0.3\n",
    "    ax.annotate(\n",
    "        '', xy=end, xytext=arrow_start,\n",
    "        arrowprops=dict(arrowstyle='-|>', color=color, lw=linewidth, shrinkA=0, shrinkB=0),\n",
    "        zorder=11\n",
    "    )\n",
    "\n",
    "    # Annotate the z value near the arc\n",
    "    label_pos = ghost_center + v * r * 1.2\n",
    "    ax.text(label_pos[0], label_pos[1],\n",
    "            f'{z_value:.1f}',\n",
    "            ha='center', va='center',\n",
    "            fontsize=16, fontweight='bold',\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.8, pad=2),\n",
    "            color=color,\n",
    "            zorder=12)\n",
    "\n",
    "def create_advanced_connectogram(matrix, labels, save_str='default', significant_threshold=3.7, near_threshold=3.4, title=None):\n",
    "    \"\"\"\n",
    "    Create an advanced connectogram visualization using matplotlib.\n",
    "\n",
    "    This function creates a circular visualization of connections between nodes (electrodes),\n",
    "    with support for different connection strengths, internal arcs, and automatic label placement.\n",
    "    Self-connections are drawn as external arcs using self_connection_plot().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : numpy.ndarray\n",
    "        Matrix of Bonferroni values (destinations × sources)\n",
    "        The matrix should be square with dimensions matching the length of labels\n",
    "    labels : list\n",
    "        List of electrode labels (e.g., ['F3', 'FC5', etc.])\n",
    "    save_str : str, optional\n",
    "        String for saving the output files, by default 'default'\n",
    "    significant_threshold : float, optional\n",
    "        Threshold for significant connections (|z| ≥ 3.7, p ≤ 0.1), by default 3.7\n",
    "    near_threshold : float, optional\n",
    "        Threshold for near-significant connections (|z| ≥ 3.4, p ≤ 0.2), by default 3.4\n",
    "    title : str, optional\n",
    "        Title for the plot ('Controls' or 'Reading Difficulties'), by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function saves the plot as PNG and EPS files and displays it\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Significant connections (|z| ≥ 3.7) are shown in black with linewidth 6\n",
    "    - Near-significant connections (3.4 ≤ |z| < 3.7) are shown in gray with linewidth 3\n",
    "    - Connections are automatically curved inward to avoid edge overlaps\n",
    "    - Labels are positioned close to their connections\n",
    "    - Far connections (node distance > 5) are drawn as straight lines\n",
    "    - Self-connections are drawn as external arcs using self_connection_plot()\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(18, 18))\n",
    "\n",
    "    if title:\n",
    "        plt.title(title, pad=20, fontsize=32, fontweight='bold')\n",
    "\n",
    "    n_nodes = len(labels)\n",
    "    radius = 10\n",
    "    node_radius = 0.7\n",
    "    angles = np.linspace(0, 2*np.pi, n_nodes, endpoint=False)\n",
    "\n",
    "    node_positions = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        x = radius * np.cos(angles[i])\n",
    "        y = radius * np.sin(angles[i])\n",
    "        node_positions[label] = (x, y)\n",
    "\n",
    "    def nodes_between(src_idx, dst_idx):\n",
    "        dist = abs(dst_idx - src_idx)\n",
    "        return min(dist, n_nodes - dist)\n",
    "\n",
    "    def get_normal_vector(dx, dy):\n",
    "        norm = np.sqrt(dx*dx + dy*dy)\n",
    "        if norm < 1e-10:\n",
    "            return np.array([0, 1])\n",
    "        return np.array([-dy/norm, dx/norm])\n",
    "\n",
    "    def get_connection_style(src_pos, dst_pos, node_dist):\n",
    "        mid_x = (src_pos[0] + dst_pos[0]) / 2\n",
    "        mid_y = (src_pos[1] + dst_pos[1]) / 2\n",
    "        to_mid = np.array([mid_x, mid_y])\n",
    "        dist_from_center = np.sqrt(np.sum(to_mid**2))\n",
    "        if node_dist > 5:\n",
    "            return \"arc3,rad=0\"\n",
    "        if dist_from_center > radius * 0.9:\n",
    "            if node_dist <= 1:\n",
    "                return \"arc3,rad=-0.8\"\n",
    "            elif node_dist <= 3:\n",
    "                return \"arc3,rad=-0.6\"\n",
    "            else:\n",
    "                return \"arc3,rad=-0.4\"\n",
    "        else:\n",
    "            if node_dist <= 1:\n",
    "                return \"arc3,rad=0.5\"\n",
    "            elif node_dist <= 3:\n",
    "                return \"arc3,rad=0.3\"\n",
    "            else:\n",
    "                return \"arc3,rad=0.2\"\n",
    "\n",
    "    drawn_edges = set()\n",
    "\n",
    "    # Draw near-significant and significant connections (excluding self-connections)\n",
    "    for i, src in enumerate(labels):\n",
    "        for j, dst in enumerate(labels):\n",
    "            if i == j:\n",
    "                continue  # Skip self-connections here\n",
    "            zval = abs(matrix[j, i])\n",
    "            if near_threshold <= zval < significant_threshold:\n",
    "                if (src, dst) not in drawn_edges:\n",
    "                    src_pos = node_positions[src]\n",
    "                    dst_pos = node_positions[dst]\n",
    "                    node_dist = nodes_between(i, j)\n",
    "                    connectionstyle = get_connection_style(src_pos, dst_pos, node_dist)\n",
    "                    con = ConnectionPatch(\n",
    "                        xyA=src_pos, xyB=dst_pos,\n",
    "                        coordsA=\"data\", coordsB=\"data\",\n",
    "                        axesA=ax, axesB=ax,\n",
    "                        color='#CCCCCC',\n",
    "                        linewidth=3,\n",
    "                        connectionstyle=connectionstyle,\n",
    "                        arrowstyle='<|-',\n",
    "                        mutation_scale=20,\n",
    "                        shrinkA=node_radius*40,\n",
    "                        shrinkB=node_radius*40,\n",
    "                        zorder=1\n",
    "                    )\n",
    "                    ax.add_patch(con)\n",
    "                    # Add value label\n",
    "                    mid_x = (src_pos[0] + dst_pos[0]) / 2\n",
    "                    mid_y = (src_pos[1] + dst_pos[1]) / 2\n",
    "                    dx = dst_pos[0] - src_pos[0]\n",
    "                    dy = dst_pos[1] - src_pos[1]\n",
    "                    normal = get_normal_vector(dx, dy)\n",
    "                    offset = 0.3\n",
    "                    label_pos = np.array([mid_x, mid_y]) + normal * offset\n",
    "                    plt.text(label_pos[0], label_pos[1],\n",
    "                            f'{matrix[j, i]:.1f}',\n",
    "                            horizontalalignment='center',\n",
    "                            verticalalignment='center',\n",
    "                            fontsize=24,\n",
    "                            fontweight='bold',\n",
    "                            color='#666666',\n",
    "                            bbox=dict(facecolor='white',\n",
    "                                    edgecolor='none',\n",
    "                                    alpha=0.8,\n",
    "                                    pad=2),\n",
    "                            zorder=4)\n",
    "                    drawn_edges.add((src, dst))\n",
    "\n",
    "    for i, src in enumerate(labels):\n",
    "        for j, dst in enumerate(labels):\n",
    "            if i == j:\n",
    "                continue # Skip self connections here\n",
    "            zval = abs(matrix[j, i])\n",
    "            if zval >= significant_threshold:\n",
    "                if (src, dst) not in drawn_edges:\n",
    "                    src_pos = node_positions[src]\n",
    "                    dst_pos = node_positions[dst]\n",
    "                    node_dist = nodes_between(i, j)\n",
    "                    connectionstyle = get_connection_style(src_pos, dst_pos, node_dist)\n",
    "                    con = ConnectionPatch(\n",
    "                        xyA=src_pos, xyB=dst_pos,\n",
    "                        coordsA=\"data\", coordsB=\"data\",\n",
    "                        axesA=ax, axesB=ax,\n",
    "                        color='black',\n",
    "                        linewidth=6,\n",
    "                        connectionstyle=connectionstyle,\n",
    "                        arrowstyle='<|-',\n",
    "                        mutation_scale=20,\n",
    "                        shrinkA=node_radius*40,\n",
    "                        shrinkB=node_radius*40,\n",
    "                        zorder=2\n",
    "                    )\n",
    "                    ax.add_patch(con)\n",
    "                    # Add value label\n",
    "                    mid_x = (src_pos[0] + dst_pos[0]) / 2\n",
    "                    mid_y = (src_pos[1] + dst_pos[1]) / 2\n",
    "                    dx = dst_pos[0] - src_pos[0]\n",
    "                    dy = dst_pos[1] - src_pos[1]\n",
    "                    normal = get_normal_vector(dx, dy)\n",
    "                    offset = 0.3\n",
    "                    label_pos = np.array([mid_x, mid_y]) + normal * offset\n",
    "                    plt.text(label_pos[0], label_pos[1],\n",
    "                            f'{matrix[j, i]:.1f}',\n",
    "                            horizontalalignment='center',\n",
    "                            verticalalignment='center',\n",
    "                            fontsize=24,\n",
    "                            fontweight='bold',\n",
    "                            bbox=dict(facecolor='white',\n",
    "                                    edgecolor='none',\n",
    "                                    alpha=0.8,\n",
    "                                    pad=2),\n",
    "                            zorder=4)\n",
    "                    drawn_edges.add((src, dst))\n",
    "\n",
    "    # Draw self-connections\n",
    "    for i, label in enumerate(labels):\n",
    "        zval = abs(matrix[i, i])\n",
    "        if zval >= significant_threshold:\n",
    "            self_connection_plot(\n",
    "                ax=ax,\n",
    "                pos=node_positions[label],\n",
    "                node_radius=node_radius,\n",
    "                z_value=matrix[i, i],\n",
    "                color='black',\n",
    "                linewidth=6,\n",
    "                center=(0,0)\n",
    "            )\n",
    "        elif zval >= near_threshold:\n",
    "            self_connection_plot(\n",
    "                ax=ax,\n",
    "                pos=node_positions[label],\n",
    "                node_radius=node_radius,\n",
    "                z_value=matrix[i, i],\n",
    "                color='#CCCCCC',\n",
    "                linewidth=3,\n",
    "                center=(0,0)\n",
    "            )\n",
    "\n",
    "    # Draw nodes\n",
    "    for label, pos in node_positions.items():\n",
    "        for offset in [0.15, 0.1, 0.05]:\n",
    "            shadow = Circle(\n",
    "                (pos[0]-offset/2, pos[1]-offset/2),\n",
    "                radius=node_radius,\n",
    "                facecolor='gray',\n",
    "                alpha=0.1,\n",
    "                zorder=5\n",
    "            )\n",
    "            ax.add_patch(shadow)\n",
    "        circle = Circle(\n",
    "            pos,\n",
    "            radius=node_radius,\n",
    "            facecolor='white',\n",
    "            edgecolor='red',\n",
    "            linewidth=2,\n",
    "            zorder=6\n",
    "        )\n",
    "        ax.add_patch(circle)\n",
    "        plt.text(pos[0], pos[1],\n",
    "                label,\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=24,\n",
    "                fontweight='bold',\n",
    "                zorder=7)\n",
    "\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], color='black', linewidth=6, \n",
    "                  label=f'|z| ≥ {significant_threshold:.1f} (p ≤ 0.1)'),\n",
    "        plt.Line2D([0], [0], color='#CCCCCC', linewidth=3, \n",
    "                  label=f'|z| ≥ {near_threshold:.1f} (p ≤ 0.2)')\n",
    "    ]\n",
    "    legend = ax.legend(handles=legend_elements,\n",
    "                      loc='upper right',\n",
    "                      title='Bonferroni Value',\n",
    "                      fontsize=24,\n",
    "                      title_fontsize=28,\n",
    "                      frameon=True,\n",
    "                      facecolor='white',\n",
    "                      edgecolor='none')\n",
    "    legend.get_frame().set_alpha(1.0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    limit = radius + 2\n",
    "    ax.set_xlim(-limit, limit)\n",
    "    ax.set_ylim(-limit, limit)\n",
    "    plt.savefig(f'Figures/connectogram_{save_str}.png',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight',\n",
    "                facecolor='white',\n",
    "                edgecolor='none')\n",
    "    plt.savefig(f'Figures/connectogram_{save_str}.eps',\n",
    "                format='eps',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight',\n",
    "                facecolor='white',\n",
    "                edgecolor='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Reading Data</h2>\n",
    "\n",
    "Once all the probability matrices of all the subjects have been obtained, they are converted into row vectors and concatenated into a matrix of results according to the class to which they belong. In our case we wanted to compare Control subjects versus subjects with Reading Difficulties for different auditory stimuli (4.8Hz, 16Hz and 40Hz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files for each frequency scenario\n",
    "filename_save = [['results_4_8Hz_Controls.pkl','results_4_8Hz_Difficulties.pkl'],\n",
    "                 ['results_16Hz_Controls.pkl','results_16Hz_Difficulties.pkl'],\n",
    "                 ['results_40Hz_Controls.pkl','results_40Hz_Difficulties.pkl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq_idx, (controls_file, reading_difficulties_file) in enumerate(filename_save):\n",
    "\n",
    "    #### Controls ####\n",
    "    ##################\n",
    "\n",
    "    # Load Data\n",
    "    with open(controls_file, 'rb') as f:\n",
    "        controls_probability_matrices = pickle.load(f)\n",
    "    \n",
    "    # Convert the list of matrices to a NumPy array\n",
    "    controls_probability_matrices_array = np.array(controls_probability_matrices)\n",
    "\n",
    "    # Compute the real means for each column (source-destination connections)\n",
    "    controls_real_means = np.mean(controls_probability_matrices_array, axis=0)\n",
    "\n",
    "    # Initialize array to store the means from the permutations\n",
    "    controls_surrogate_means = np.zeros((G_nSurrogates, controls_probability_matrices_array.shape[1]))\n",
    "\n",
    "    # Generate the permutations and calculate means\n",
    "    for s in range(G_nSurrogates):\n",
    "        controls_permuted_matrix = np.random.permutation(controls_probability_matrices_array.flatten()).reshape(controls_probability_matrices_array.shape)\n",
    "        controls_surrogate_means[s, :] = np.mean(controls_permuted_matrix, axis=0)\n",
    "    \n",
    "    # Calculate the mean and standard deviation from the surrogate data (null distribution)\n",
    "    controls_surrogate_mean = np.mean(controls_surrogate_means, axis=0)\n",
    "    controls_surrogate_std = np.std(controls_surrogate_means, axis=0)\n",
    "\n",
    "    # Compute z-scores for the real connections\n",
    "    controls_z_scores = np.zeros(controls_real_means.shape)\n",
    "    controls_non_zero_std = controls_surrogate_std > 0  # Avoid division by zero\n",
    "    controls_z_scores[controls_non_zero_std] = (controls_real_means[controls_non_zero_std] - controls_surrogate_mean[controls_non_zero_std]) / controls_surrogate_std[controls_non_zero_std]\n",
    "\n",
    "    # Second Bonferroni correction to determine the significance threshold\n",
    "    controls_z_threshold_bonferroni = norm.ppf(1 - G_Alpha / controls_probability_matrices_array.shape[1])\n",
    "\n",
    "    # Identify significant connections using Bonferroni correction\n",
    "    controls_significant_connections_bonferroni = np.where(np.abs(controls_z_scores) > controls_z_threshold_bonferroni)\n",
    "\n",
    "    # Display significant connections based on Bonferroni correction\n",
    "    print(f\"[CONTROLS] Bonferroni corrected z-threshold: {controls_z_threshold_bonferroni}\")\n",
    "    print(\"[CONTROLS] Significant connections (source -> destination, z-score):\")\n",
    "    for idx in controls_significant_connections_bonferroni[0]:\n",
    "        i, j = divmod(idx, G_nChannels)\n",
    "        print(f\"\\tConnection from {G_EEG_labels[i]} to {G_EEG_labels[j]} with z-score: {controls_z_scores[idx]:.3f}\")\n",
    "    \n",
    "    # Convert z-scores to square matrices of size G_nChannels x G_nChannels\n",
    "    controls_z_scores_matrix = controls_z_scores.reshape(G_nChannels, G_nChannels)\n",
    "\n",
    "    # Identify connections above near significant threshold\n",
    "    controls_significant_connections_fixed = np.where(np.abs(controls_z_scores_matrix) > z_alpha_bonferroni_near)\n",
    "    controls_significant_connections_posterior_analysis = {(i, j) for i, j in zip(controls_significant_connections_fixed[0], controls_significant_connections_fixed[1])}\n",
    "    print(f\"[CONTROLS] Evaluating connections (source -> destination) with a z-score above near significant threshold ({z_alpha_bonferroni_near})\")\n",
    "    for i, j in controls_significant_connections_posterior_analysis:\n",
    "        print(f\"\\tConnection from {G_EEG_labels[i]} to {G_EEG_labels[j]} with z-score: {controls_z_scores_matrix[i, j]:.3f}\")\n",
    "    \n",
    "    # Connectogram showing results\n",
    "    create_advanced_connectogram(controls_z_scores_matrix, G_EEG_labels, \n",
    "                                 save_str=f\"{controls_file}_Updated\",\n",
    "                                 title=\"Controls\")\n",
    "\n",
    "    #### Reading Difficulties ####\n",
    "    ##############################\n",
    "\n",
    "    # Load Data\n",
    "    with open(reading_difficulties_file, 'rb') as f:\n",
    "        reading_difficulties_probability_matrices = pickle.load(f)\n",
    "    \n",
    "    # Convert the list of matrices to a NumPy array\n",
    "    reading_difficulties_probability_matrices_array = np.array(reading_difficulties_probability_matrices)\n",
    "\n",
    "    # Compute the real means for each column (source-destination connections)\n",
    "    reading_difficulties_real_means = np.mean(reading_difficulties_probability_matrices_array, axis=0)\n",
    "\n",
    "    # Initialize array to store the means from the permutations\n",
    "    reading_difficulties_surrogate_means = np.zeros((G_nSurrogates, reading_difficulties_probability_matrices_array.shape[1]))\n",
    "\n",
    "    # Generate the permutations and calculate means\n",
    "    for s in range(G_nSurrogates):\n",
    "        reading_difficulties_permuted_matrix = np.random.permutation(reading_difficulties_probability_matrices_array.flatten()).reshape(reading_difficulties_probability_matrices_array.shape)\n",
    "        reading_difficulties_surrogate_means[s, :] = np.mean(reading_difficulties_permuted_matrix, axis=0)\n",
    "    \n",
    "    # Calculate the mean and standard deviation from the surrogate data (null distribution)\n",
    "    reading_difficulties_surrogate_mean = np.mean(reading_difficulties_surrogate_means, axis=0)\n",
    "    reading_difficulties_surrogate_std = np.std(reading_difficulties_surrogate_means, axis=0)\n",
    "\n",
    "    # Compute z-scores for the real connections\n",
    "    reading_difficulties_z_scores = np.zeros(reading_difficulties_real_means.shape)\n",
    "    reading_difficulties_non_zero_std = reading_difficulties_surrogate_std > 0  # Avoid division by zero\n",
    "    reading_difficulties_z_scores[reading_difficulties_non_zero_std] = (reading_difficulties_real_means[reading_difficulties_non_zero_std] - reading_difficulties_surrogate_mean[reading_difficulties_non_zero_std]) / reading_difficulties_surrogate_std[reading_difficulties_non_zero_std]\n",
    "\n",
    "    # Second Bonferroni correction to determine the significance threshold\n",
    "    reading_difficulties_z_threshold_bonferroni = norm.ppf(1 - G_Alpha / reading_difficulties_probability_matrices_array.shape[1])\n",
    "\n",
    "    # Identify significant connections using Bonferroni correction\n",
    "    reading_difficulties_significant_connections_bonferroni = np.where(np.abs(reading_difficulties_z_scores) > reading_difficulties_z_threshold_bonferroni)\n",
    "\n",
    "    # Display significant connections based on Bonferroni correction\n",
    "    print(f\"[READING DIFFICULTIES] Bonferroni corrected z-threshold: {reading_difficulties_z_threshold_bonferroni}\")\n",
    "    print(\"[READING DIFFICULTIES] Significant connections (source -> destination, z-score):\")\n",
    "    for idx in reading_difficulties_significant_connections_bonferroni[0]:\n",
    "        i, j = divmod(idx, G_nChannels)\n",
    "        print(f\"\\tConnection from {G_EEG_labels[i]} to {G_EEG_labels[j]} with z-score: {reading_difficulties_z_scores[idx]:.3f}\")\n",
    "\n",
    "    # Convert z-scores to square matrices of size G_nChannels x G_nChannels\n",
    "    reading_difficulties_z_scores_matrix = reading_difficulties_z_scores.reshape(G_nChannels, G_nChannels)\n",
    "\n",
    "    # Identify connections above near significant threshold\n",
    "    reading_difficulties_significant_connections_fixed = np.where(np.abs(reading_difficulties_z_scores_matrix) > z_alpha_bonferroni_near)\n",
    "    reading_difficulties_significant_connections_posterior_analysis = {(i, j) for i, j in zip(reading_difficulties_significant_connections_fixed[0], reading_difficulties_significant_connections_fixed[1])}\n",
    "    print(f\"[READING DIFFICULTIES] Evaluating connections (source -> destination) with a z-score above near significant threshold ({z_alpha_bonferroni_near})\")\n",
    "    for i, j in reading_difficulties_significant_connections_posterior_analysis:\n",
    "        print(f\"\\tConnection from {G_EEG_labels[i]} to {G_EEG_labels[j]} with z-score: {reading_difficulties_z_scores_matrix[i, j]:.3f}\")\n",
    "    \n",
    "    # Connectogram showing results\n",
    "    create_advanced_connectogram(reading_difficulties_z_scores_matrix, G_EEG_labels, \n",
    "                                 save_str=f\"{reading_difficulties_file}_Updated\",\n",
    "                                 title=\"Reading_Difficulties\")\n",
    "    \n",
    "    #### Classification ####\n",
    "    ########################\n",
    "\n",
    "    # Combine significant connections from both groups for the current frequency\n",
    "    all_significant_connections_posterior_analysis = controls_significant_connections_posterior_analysis.union(reading_difficulties_significant_connections_posterior_analysis)\n",
    "\n",
    "    # Initialize X and y for the current frequency scenario\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Convert the significant (i, j) pairs into linear indices for accessing flat arrays\n",
    "    linear_indices = [i * G_nChannels + j for i, j in all_significant_connections_posterior_analysis]\n",
    "\n",
    "    # Populate X and y for controls group\n",
    "    for control_prob_matrix in controls_probability_matrices_array:\n",
    "        # Extract probability values for each significant connection using linear indices\n",
    "        row = [control_prob_matrix[idx] for idx in linear_indices]\n",
    "        X.append(row)\n",
    "        y.append(0)  # Labeled as control\n",
    "\n",
    "    # Populate X and y for reading difficulties group\n",
    "    for reading_difficulties_prob_matrix in reading_difficulties_probability_matrices_array:\n",
    "        # Extract probability values for each significant connection using linear indices\n",
    "        row = [reading_difficulties_prob_matrix[idx] for idx in linear_indices]\n",
    "        X.append(row)\n",
    "        y.append(1)  # Labeled as reading difficulties\n",
    "\n",
    "    # Convert X and y to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Shuffle X and y together to randomize the order for robust training\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    # Print the shape of X and y to confirm correct structure\n",
    "    print(f\"Predictor matrix (X) shape for frequency {freq_idx + 1}: {X.shape}\")\n",
    "    print(f\"Response vector (y) shape for frequency {freq_idx + 1}: {y.shape}\")\n",
    "\n",
    "    # Train and evaluate the model on the real data\n",
    "    real_accuracy, real_balanced_accuracy, real_auc, real_precision, real_recall, real_specificity, real_f1 = train_evaluate_xgboost(X, y)\n",
    "    print(\"\\n=== Classification Results ===\")\n",
    "    print(f\"\\tAccuracy: {real_accuracy:.3f}\")\n",
    "    print(f\"\\tBalanced Accuracy: {real_balanced_accuracy:.3f}\")\n",
    "    print(f\"\\tAUC: {real_auc:.3f}\")\n",
    "    print(f\"\\tPrecision: {real_precision:.3f}\")\n",
    "    print(f\"\\tRecall (Sensitivity): {real_recall:.3f}\")\n",
    "    print(f\"\\tSpecificity: {real_specificity:.3f}\")\n",
    "    print(f\"\\tF1-Score: {real_f1:.3f}\")\n",
    "\n",
    "    #### Permutation Test ####\n",
    "    ##########################\n",
    "\n",
    "    # Temporarily save the classification metrics for each iteration of the permutation test\n",
    "    accuracy_permuted = []\n",
    "    balanced_accuracy_permuted = []\n",
    "    auc_permuted = []\n",
    "    precision_permuted = []\n",
    "    recall_permuted = []\n",
    "    specificity_permuted = []\n",
    "    f1_permuted = []\n",
    "\n",
    "    # Perform permutation test\n",
    "    for perm in range(G_nPermutations):\n",
    "        # Randomly swap labels\n",
    "        y_permuted = np.random.permutation(y)\n",
    "        # Training and evaluation of the model with swaped labels\n",
    "        perm_accuracy, perm_balanced_accuracy, perm_auc, perm_precision, perm_recall, perm_specificity, perm_f1 = train_evaluate_xgboost(X, y_permuted)\n",
    "        # Save metrics\n",
    "        accuracy_permuted.append(perm_accuracy)\n",
    "        balanced_accuracy_permuted.append(perm_balanced_accuracy)\n",
    "        auc_permuted.append(perm_auc)\n",
    "        precision_permuted.append(perm_precision)\n",
    "        recall_permuted.append(perm_recall)\n",
    "        specificity_permuted.append(perm_specificity)\n",
    "        f1_permuted.append(perm_f1)\n",
    "\n",
    "    # Converting lists to NumPy arrays to calculate statistics\n",
    "    accuracy_permuted = np.array(accuracy_permuted)\n",
    "    balanced_accuracy_permuted = np.array(balanced_accuracy_permuted)\n",
    "    auc_permuted = np.array(auc_permuted)\n",
    "    precision_permuted = np.array(precision_permuted)\n",
    "    recall_permuted = np.array(recall_permuted)\n",
    "    specificity_permuted = np.array(specificity_permuted)\n",
    "    f1_permuted = np.array(f1_permuted)\n",
    "\n",
    "    # Calculate the p-values for each metric\n",
    "    p_accuracy = np.mean(accuracy_permuted >= real_accuracy)\n",
    "    p_balanced_accuracy = np.mean(balanced_accuracy_permuted >= real_balanced_accuracy)\n",
    "    p_auc = np.mean(auc_permuted >= real_auc)\n",
    "    p_precision = np.mean(precision_permuted >= real_precision)\n",
    "    p_recall = np.mean(recall_permuted >= real_recall)\n",
    "    p_specificity = np.mean(specificity_permuted >= real_specificity)\n",
    "    p_f1 = np.mean(f1_permuted >= real_f1)\n",
    "\n",
    "    print(\"\\n=== Permutation Test Results (p-values) ===\")\n",
    "    print(f\"p-value for Accuracy: {p_accuracy:.3f}\")\n",
    "    print(f\"p-value for Balanced Accuracy: {p_balanced_accuracy:.3f}\")\n",
    "    print(f\"p-value for AUC: {p_auc:.3f}\")\n",
    "    print(f\"p-value for Precision: {p_precision:.3f}\")\n",
    "    print(f\"p-value for Recall (Sensitivity): {p_recall:.3f}\")\n",
    "    print(f\"p-value for Specificity: {p_specificity:.3f}\")\n",
    "    print(f\"p-value for F1-Score: {p_f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
